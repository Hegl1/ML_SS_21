*
Test accuracy (dropout)
-
v_acc: 0.5299586776859504
-
v_acc: 0.6353305785123967
-
v_acc: 0.7014462809917356
-
v_acc: 0.7091942148760331
-
v_acc: 0.753099173553719
-
v_acc: 0.7536157024793388
-
v_acc: 0.7954545454545454
-
v_acc: 0.7928719008264463
-
v_acc: 0.8088842975206612
-
v_acc: 0.8290289256198347
-
v_acc: 0.8223140495867769
-
v_acc: 0.8321280991735537
-
v_acc: 0.831095041322314
-
v_acc: 0.8331611570247934
-
v_acc: 0.8316115702479339
-
v_acc: 0.8357438016528925
-
v_acc: 0.8548553719008265
-
v_acc: 0.859504132231405
-
v_acc: 0.8424586776859504
-
v_acc: 0.8589876033057852
-
v_acc: 0.8533057851239669
-
v_acc: 0.8662190082644629
-
v_acc: 0.8641528925619835
-
v_acc: 0.8636363636363636
-
v_acc: 0.8600206611570248
-
v_acc: 0.8605371900826446
-
v_acc: 0.8631198347107438
-
v_acc: 0.8672520661157025
-
v_acc: 0.8667355371900827
-
v_acc: 0.871900826446281
*
Train accuracy (drouput)
-
t_acc: 0.5550103305785123
-
t_acc: 0.6726497933884298
-
t_acc: 0.7613636363636364
-
t_acc: 0.7749225206611571
-
t_acc: 0.8305785123966942
-
t_acc: 0.8471074380165289
-
t_acc: 0.8757747933884298
-
t_acc: 0.8799070247933884
-
t_acc: 0.9129648760330579
-
t_acc: 0.9198088842975206
-
t_acc: 0.9278150826446281
-
t_acc: 0.9293646694214877
-
t_acc: 0.9350464876033058
-
t_acc: 0.9461518595041323
-
t_acc: 0.9478305785123967
-
t_acc: 0.9672004132231405
-
t_acc: 0.9664256198347108
-
t_acc: 0.9759814049586777
-
t_acc: 0.9693956611570248
-
t_acc: 0.9732696280991735
-
t_acc: 0.9790805785123967
-
t_acc: 0.9847623966942148
-
t_acc: 0.9803719008264463
-
t_acc: 0.981404958677686
-
t_acc: 0.9816632231404959
-
t_acc: 0.984504132231405
-
t_acc: 0.9882489669421488
-
t_acc: 0.9855371900826446
-
t_acc: 0.9901859504132231
-
t_acc: 0.9939307851239669
*
Train accuracy (no dropout)
-
t_acc: 0.5641787190082644
-
t_acc: 0.7141012396694215
-
t_acc: 0.765625
-
t_acc: 0.8149535123966942
-
t_acc: 0.8228305785123967
-
t_acc: 0.8713842975206612
-
t_acc: 0.9008264462809917
-
t_acc: 0.922004132231405
-
t_acc: 0.9433109504132231
-
t_acc: 0.9544163223140496
-
t_acc: 0.9767561983471075
-
t_acc: 0.9723657024793388
-
t_acc: 0.9735278925619835
-
t_acc: 0.9792097107438017
-
t_acc: 0.9923811983471075
-
t_acc: 0.9957386363636364
-
t_acc: 0.9978047520661157
-
t_acc: 0.996900826446281
-
t_acc: 0.9965134297520661
-
t_acc: 0.9935433884297521
-
t_acc: 0.9991528925619835
-
t_acc: 0.9950929752066116
-
t_acc: 0.999870867768595
-
t_acc: 1.0
-
t_acc: 1.0
-
t_acc: 1.0
-
t_acc: 1.0
-
t_acc: 1.0
-
t_acc: 1.0
-
t_acc: 1.0
*
Test accuracy (no dropout)
-
v_acc: 0.543904958677686
-
v_acc: 0.6425619834710744
-
v_acc: 0.6926652892561983
-
v_acc: 0.7365702479338843
-
v_acc: 0.7458677685950413
-
v_acc: 0.7887396694214877
-
v_acc: 0.7964876033057852
-
v_acc: 0.8083677685950413
-
v_acc: 0.8025
-
v_acc: 0.8043801652892562
-
v_acc: 0.8014256198347108
-
v_acc: 0.8019421487603306
-
v_acc: 0.8098760330578512
-
v_acc: 0.8117561983471075
-
v_acc: 0.8138223140495868
-
v_acc: 0.8210537190082644
-
v_acc: 0.8214152892561983
-
v_acc: 0.8277685950413223
-
v_acc: 0.829504132231405
-
v_acc: 0.8231198347107438
-
v_acc: 0.8207231404958677
-
v_acc: 0.8262190082644629
-
v_acc: 0.8267355371900827
-
v_acc: 0.8382851239669421
-
v_acc: 0.8298347107438017
-
v_acc: 0.8351859504132231
-
v_acc: 0.8357024793388429
-
v_acc: 0.8303512396694215
-
v_acc: 0.8334504132231405
-
v_acc: 0.8308677685950413




















































