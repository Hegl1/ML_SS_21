{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b71bda",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ccb3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Setting the path of the training dataset (that was already provided to you)\n",
    "\n",
    "running_local = True if os.getenv('JUPYTERHUB_USER') is None else False\n",
    "DATASET_PATH = \".\"\n",
    "\n",
    "# Set the location of the dataset\n",
    "if running_local:\n",
    "    # If running on your local machine, the sign_lang_train folder's path should be specified here\n",
    "    local_path = \"sign_lang_train\"\n",
    "    if os.path.exists(local_path):\n",
    "        DATASET_PATH = local_path\n",
    "else:\n",
    "    # If running on the Jupyter hub, this data folder is already available\n",
    "    # You DO NOT need to upload the data!\n",
    "        DATASET_PATH = \"/data/mlproject21/sign_lang_train\"\n",
    "        \n",
    "# Setting the path of the training dataset (that was already provided to you)\n",
    "\n",
    "running_local = True if os.getenv('JUPYTERHUB_USER') is None else False\n",
    "DATASET_PATH = \".\"\n",
    "\n",
    "# Set the location of the dataset\n",
    "if running_local:\n",
    "    # If running on your local machine, the sign_lang_train folder's path should be specified here\n",
    "    local_path = \"sign_lang_train\"\n",
    "    if os.path.exists(local_path):\n",
    "        DATASET_PATH = local_path\n",
    "else:\n",
    "    # If running on the Jupyter hub, this data folder is already available\n",
    "    # You DO NOT need to upload the data!\n",
    "        DATASET_PATH = \"/data/mlproject21/sign_lang_train\"\n",
    "\n",
    "# Utility function\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    with open(csv_file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aaebd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, utils, io\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from string import ascii_lowercase\n",
    "\n",
    "class SignLangDataset(Dataset):\n",
    "    \"\"\"Sign language dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, class_index_map=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = read_csv(os.path.join(root_dir,csv_file))\n",
    "        self.root_dir = root_dir\n",
    "        self.class_index_map = class_index_map\n",
    "        self.transform = transform\n",
    "        # List of class names in order\n",
    "        self.class_names = list(map(str, list(range(10)))) + list(ascii_lowercase)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Calculates the length of the dataset-\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns one sample (dict consisting of an image and its label)\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Read the image and labels\n",
    "        image_path = os.path.join(self.root_dir, self.data[idx][1])\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # Shape of the image should be H,W,C where C=1\n",
    "        image = np.expand_dims(image, 0)\n",
    "        # The label is the index of the class name in the list ['0','1',...,'9','a','b',...'z']\n",
    "        # because we should have integer labels in the range 0-35 (for 36 classes)\n",
    "        label = self.class_names.index(self.data[idx][0])\n",
    "                \n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20df293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_lang_dataset = SignLangDataset(csv_file=\"labels.csv\", root_dir=DATASET_PATH)\n",
    "#print(sign_lang_dataset[1]['label'])\n",
    "data_len = len(sign_lang_dataset)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * data_len)\n",
    "val_size = data_len - train_size\n",
    "train_dataset, val_dataset = random_split(sign_lang_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f4ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_for_scikit(dataset):\n",
    "    X_list = list()\n",
    "    y_list = list()\n",
    "    for data in dataset:\n",
    "        X_list.append(data['image'])\n",
    "        y_list.append(data['label'])\n",
    "    return np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de149e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7744, 16384)\n",
      "(1936, 16384)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = build_data_for_scikit(train_dataset)\n",
    "X_train = X_train.reshape(train_size, -1)\n",
    "X_test, y_test = build_data_for_scikit(val_dataset)\n",
    "X_test = X_test.reshape(val_size, -1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad3e7e",
   "metadata": {},
   "source": [
    "# Desc Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f4d6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental\n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1198f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 291 with ccp_alpha: 0.014482925279712844\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for i in range(200, len(ccp_alphas), 300):\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alphas[i])\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      clfs[-1].tree_.node_count, ccp_alphas[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b143e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(ccp_alpha=0.00012913223140495868, random_state=0), DecisionTreeClassifier(ccp_alpha=0.00023243801652892576, random_state=0), DecisionTreeClassifier(ccp_alpha=0.0003228305785123967, random_state=0), DecisionTreeClassifier(ccp_alpha=0.0004958677685950414, random_state=0), DecisionTreeClassifier(ccp_alpha=0.0010433475320776988, random_state=0)]\n",
      "[0.8929493801652892, 0.8607954545454546, 0.7957128099173554, 0.7004132231404959, 0.49599690082644626]\n",
      "[0.37964876033057854, 0.38016528925619836, 0.37706611570247933, 0.381198347107438, 0.3517561983471074]\n"
     ]
    }
   ],
   "source": [
    "print(clfs)\n",
    "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "184cb295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_sklearn = DecisionTreeClassifier(criterion='gini')\n",
    "tree_sklearn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dd0643c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.368801652892562\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = tree_sklearn.score(X_train, y_train)\n",
    "accuracy_test = tree_sklearn.score(X_test, y_test)\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f0836",
   "metadata": {},
   "source": [
    "# k nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9681975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634297520661157\n",
      "0.7784090909090909\n",
      "0.7747933884297521\n",
      "0.7778925619834711\n",
      "0.765495867768595\n",
      "0.7582644628099173\n",
      "0.7541322314049587\n",
      "0.7489669421487604\n",
      "0.737603305785124\n",
      "0.7396694214876033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(2,12):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa011530",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33eb1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7e0891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.45646219\n",
      "Iteration 2, loss = 3.25211696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(200,), max_iter=30, random_state=1,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,), random_state=1, verbose=True, max_iter = 30)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f9745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2815082644628099\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, y_test))\n",
    "print(clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef651206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
