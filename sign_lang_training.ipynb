{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43dce40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe8515d8e0eb388ce79930ea7b6c63cb",
     "grade": false,
     "grade_id": "cell-14bdc41e163110b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Sign Language Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54721c43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "340354f8bc0f0c53961e7f6762bd47e8",
     "grade": false,
     "grade_id": "cell-51db7564f748aef7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The Sign Language Dataset consists of 9680 grayscale images of hand signs for the digits 0-9 and the alphabets a-z. Thus, this is a multiclass classification problem with 36 classes. Your task is to build a machine learning model that can accurately classify images from this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab59337",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfd3766dc129d20a384b6fe374f898ba",
     "grade": false,
     "grade_id": "cell-e4af33c6fde73887",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "You **do not** need to upload any data. Both the visible training dataset and the hidden test dataset are already available on the Jupyter hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d9afa3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef93277d6faf4a26d52b648647386063",
     "grade": false,
     "grade_id": "cell-8c7257ef51480021",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358bb5c3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a20016a3ec4e174980204fdb21a3c57",
     "grade": false,
     "grade_id": "cell-636bfe55501bec94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Setting the path of the training dataset (that was already provided to you)\n",
    "\n",
    "running_local = True if os.getenv('JUPYTERHUB_USER') is None else False\n",
    "DATASET_PATH = \".\"\n",
    "\n",
    "# Set the location of the dataset\n",
    "if running_local:\n",
    "    # If running on your local machine, the sign_lang_train folder's path should be specified here\n",
    "    local_path = \"sign_lang_train\"\n",
    "    if os.path.exists(local_path):\n",
    "        DATASET_PATH = local_path\n",
    "else:\n",
    "    # If running on the Jupyter hub, this data folder is already available\n",
    "    # You DO NOT need to upload the data!\n",
    "        DATASET_PATH = \"/data/mlproject21/sign_lang_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdde19a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80e80b0135d964a577c59224e58423d4",
     "grade": false,
     "grade_id": "cell-8532dde78b48d38e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Utility function\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    with open(csv_file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34c2f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc0334c0cfa0645319a201d00563c638",
     "grade": false,
     "grade_id": "cell-f6ce53d70b7a4b20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data Loading using PyTorch\n",
    "\n",
    "For creating and training your model, you can work with any machine learning library of your choice. \n",
    "\n",
    "If you choose to work with [PyTorch](https://pytorch.org/), you will need to create your own [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class for loading the data. This is provided below. See [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for a nice example of how to create a custom data loading pipeline in PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df77684",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b92fa8c2a2c39e1bcfc5d5f36bfdc0a2",
     "grade": false,
     "grade_id": "cell-0e305bc0958e0408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, utils, io\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from string import ascii_lowercase\n",
    "\n",
    "class SignLangDataset(Dataset):\n",
    "    \"\"\"Sign language dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, class_index_map=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = read_csv(os.path.join(root_dir,csv_file))\n",
    "        self.root_dir = root_dir\n",
    "        self.class_index_map = class_index_map\n",
    "        self.transform = transform\n",
    "        # List of class names in order\n",
    "        self.class_names = list(map(str, list(range(10)))) + list(ascii_lowercase)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Calculates the length of the dataset-\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns one sample (dict consisting of an image and its label)\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Read the image and labels\n",
    "        image_path = os.path.join(self.root_dir, self.data[idx][1])\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # Shape of the image should be H,W,C where C=1\n",
    "        image = np.expand_dims(image, 0)\n",
    "        # The label is the index of the class name in the list ['0','1',...,'9','a','b',...'z']\n",
    "        # because we should have integer labels in the range 0-35 (for 36 classes)\n",
    "        label = self.class_names.index(self.data[idx][0])\n",
    "                \n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2ee46",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Dataloaders for training and testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f31fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object\n",
    "sign_lang_dataset = SignLangDataset(csv_file=\"labels.csv\", root_dir=DATASET_PATH)#, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))]))\n",
    "\n",
    "# Size of the entire dataset\n",
    "data_len = len(sign_lang_dataset)\n",
    "\n",
    "# What percentage of the dataset to use for training\n",
    "# The remaining images will go into the validation set\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Calculate the size of the training and validation sets\n",
    "train_size = int(train_ratio * data_len)\n",
    "val_size = data_len - train_size\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset, val_dataset = random_split(sign_lang_dataset, [train_size, val_size])\n",
    "\n",
    "# Create Dataloader objects for training and validation\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=64,\n",
    "                              shuffle=True, \n",
    "                              num_workers=0)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=64,\n",
    "                            shuffle=True, \n",
    "                            num_workers=0)\n",
    "\n",
    "leaderboard_dataloader = DataLoader(sign_lang_dataset, \n",
    "                                    batch_size=64, \n",
    "                                    shuffle=True, \n",
    "                                    num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a693e",
   "metadata": {},
   "source": [
    "## Definition of our ANN\n",
    "\n",
    "In the following cell we define our artificial neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd6a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Follow these steps:\n",
    "        #\n",
    "        # Flatten the input x keeping the batch dimension the same\n",
    "        # Use the relu activation on the output of self.fc1(x)\n",
    "        # Use the relu activation on the output of self.fc2(x)\n",
    "        # Pass x through fc3 but do not apply any activation function (think why not?)\n",
    "        \n",
    "        \n",
    "        # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "        #print(self.input_size)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x  # Return x (logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ed34c",
   "metadata": {},
   "source": [
    "## Definition of hyperparameters (TODO: GRID SEARCH FOR BETTER PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0129f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0065 \n",
    "INPUT_SIZE = 16384 #Size of one image (128 x 128)\n",
    "OUTPUT_SIZE = 36 #number of different labels\n",
    "HIDDEN_SIZE = 400 #bigger then 400 seems useless with the current params\n",
    "MOMENT = 0.94\n",
    "NUM_EPOCHS = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf95c7",
   "metadata": {},
   "source": [
    "## Function to create and initialize a fresh neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305dd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_init_ann():\n",
    "    ann = Net(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    opti = optim.SGD(ann.parameters(), lr=LEARNING_RATE, momentum=MOMENT)\n",
    "    return ann, crit, opti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3fd595",
   "metadata": {},
   "source": [
    "## Function to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217ced88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network_pytorch_minibatch(net, train_loader, optimizer, criterion, num_epochs):\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for _, data in enumerate(tqdm(train_loader)):    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net((data['image']/255))\n",
    "            loss = criterion(outputs, data['label'])\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878addf8",
   "metadata": {},
   "source": [
    "## Function to save the trained network to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5aa26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_net(net):\n",
    "    torch.save(net.state_dict(), \"fresh_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b61f6",
   "metadata": {},
   "source": [
    "## Train a fresh network\n",
    "If you want to train and save a fresh network, uncomment the lines below.\n",
    "Attention: your old saved network gets overwritten during this process.\n",
    "Attention_2: currently only a fraction of the data is used for training. \n",
    "TODO: Train w whole dataset before handing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7521422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/152 [00:00<?, ?it/s]/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n",
      "  8%|▊         | 12/152 [00:05<00:56,  2.49it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-640f5c70e91a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_and_init_ann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_neural_network_pytorch_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaderboard_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-43c7ba3e9a2a>\u001b[0m in \u001b[0;36mtrain_neural_network_pytorch_minibatch\u001b[0;34m(net, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                     \u001b[0;31m# If no `miniters` was specified, adjust automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ann, crit, opti = create_and_init_ann()\n",
    "train_neural_network_pytorch_minibatch(ann, leaderboard_dataloader, opti, crit, NUM_EPOCHS)\n",
    "save_net(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1862537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_minibatch(net, data_loader):\n",
    "    \"\"\"\n",
    "    Calculates the overall accuracy by using minibatches\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            output = net(data['image']/255)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(data['label'].view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = correct/len(data_loader.dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73dc8ae",
   "metadata": {},
   "source": [
    "If you trained your network using the train_dataloader, you can check the accuracies with the following cell. Note that we used the **complete dataset (laederboard_dataloader)** for our final model, to get more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b494ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13300619834710745\n",
      "0.13068181818181818\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy_minibatch(ann, train_dataloader))\n",
    "print(calc_accuracy_minibatch(ann, val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725e409",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "We used the following code to search for optimal parameters. Note that we edited this several times to find the best hyperparameters (so the current search ranges do not fit the actual parameters we found). This section also contains the leader board predict function from the other notebook (just for completeness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5979bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leader_board_predict_fn(input_batch, hidden_size):\n",
    "   \n",
    "    prediction = None\n",
    "    \n",
    "    batch_size, channels, height, width = input_batch.shape\n",
    "       \n",
    "    input_batch = (input_batch/255).astype(np.float32)\n",
    "    \n",
    "    net = Net(INPUT_SIZE, hidden_size, OUTPUT_SIZE).float()\n",
    "    net.load_state_dict(torch.load(\"saved_model.pt\"))\n",
    "    net.eval()\n",
    "    data = torch.from_numpy(input_batch.astype(np.float32))\n",
    "    net_out = net(data)\n",
    "    pred = net_out.argmax(dim=1, keepdim=True)\n",
    "    output = pred.numpy().reshape((batch_size,))\n",
    "    prediction = output\n",
    "    assert prediction is not None, \"Prediction cannot be None\"\n",
    "    assert isinstance(prediction, np.ndarray), \"Prediction must be a numpy array\"\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def accuracy(dataset_path, hidden_size, max_batches=30):\n",
    "\n",
    "    # Create a Dataset object\n",
    "    sign_lang_dataset = SignLangDataset(csv_file=\"labels.csv\", root_dir=dataset_path)\n",
    "\n",
    "    # Create a Dataloader\n",
    "    sign_lang_dataloader = DataLoader(sign_lang_dataset, \n",
    "                                      batch_size=64,\n",
    "                                      shuffle=True, \n",
    "                                      drop_last=True,\n",
    "                                      num_workers=0)\n",
    "    \n",
    "    # Calculate accuracy for each batch\n",
    "    accuracies = list()\n",
    "    for batch_idx, sample in enumerate(sign_lang_dataloader):\n",
    "        x = sample[\"image\"].numpy()\n",
    "        y = sample[\"label\"].numpy()\n",
    "        prediction = leader_board_predict_fn(x, hidden_size)\n",
    "        accuracies.append(accuracy_score(y, prediction, normalize=True))\n",
    "        \n",
    "        # We will consider only the first 30 batches\n",
    "        if batch_idx == (max_batches - 1):\n",
    "            break\n",
    "\n",
    "    assert len(accuracies) == max_batches\n",
    "    \n",
    "    # Return the average accuracy\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    return mean_accuracy\n",
    "\n",
    "def calc_accuracy_minibatch(net, data_loader):\n",
    "    \"\"\"\n",
    "    Calculates the overall accuracy by using minibatches\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            output = net(data['image']/255)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(data['label'].view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = correct/len(data_loader.dataset)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grid_search():\n",
    "    params = list()\n",
    "    for lr in np.arange(0.006, 0.01, 0.001):\n",
    "        for hs in range(350, 500, 50):\n",
    "            for mm in np.arange(0.92, 0.97, 0.01):\n",
    "                for ne in range(8, 11):\n",
    "                    ann = Net(INPUT_SIZE, hs, OUTPUT_SIZE)\n",
    "                    crit = nn.CrossEntropyLoss()\n",
    "                    opti = optim.SGD(ann.parameters(), lr=lr, momentum=mm)\n",
    "                    train_neural_network_pytorch_minibatch(ann, train_dataloader, opti, crit, ne)\n",
    "                    save_net(ann)\n",
    "                    train_accuracy = calc_accuracy_minibatch(ann, train_dataloader)\n",
    "                    test_accuracy = calc_accuracy_minibatch(ann, val_dataloader)\n",
    "                    params.append((lr, hs, mm, ne, train_accuracy, test_accuracy))\n",
    "                    output = f'lr = {lr}, hs = {hs}, mm = {mm}, ne = {ne}, acc_train = {train_accuracy}, acc_test = {test_accuracy}'\n",
    "                    #print(output)\n",
    "                    with open(\"params.txt\", \"a\") as file_object:\n",
    "                        file_object.write(output)\n",
    "                        file_object.write('\\n')\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33bd3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = grid_search()\n",
    "#import pickle\n",
    "#with open(\"param_list.pyobj\", \"wb\") as dest:\n",
    "    #pickle.dump(params, dest, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#max_acc = 1e9\n",
    "#best_params = None\n",
    "#for param_set in params:\n",
    "#    if param_set[4] - param_set[5] <= max_acc:\n",
    "#        max_acc = param_set[5]\n",
    "#        best_params = param_set\n",
    "#print(max_acc)\n",
    "#print(best_params)\n",
    "#output = f'least_delta: {max_acc}, params: {best_params}'\n",
    "#with open(\"params.txt\", \"a\") as file_object:\n",
    "                        #file_object.write(output)\n",
    "                        #file_object.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229223e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
